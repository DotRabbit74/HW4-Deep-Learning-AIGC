{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvjzYcJE3E_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405700eb-5cc1-4d22-d874-99aa85e30d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ç’°å¢ƒèˆ‡è³‡æ–™å¤¾æª¢æŸ¥å®Œç•¢ï¼Œè«‹ç¹¼çºŒä¸‹ä¸€æ­¥ã€‚\n"
          ]
        }
      ],
      "source": [
        "# 1. å®‰è£å¿…è¦å¥—ä»¶\n",
        "!pip install streamlit torch torchvision grad-cam opencv-python-headless -q\n",
        "\n",
        "import os\n",
        "# æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨\n",
        "if not os.path.exists('dataset'):\n",
        "    print(\"âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ° 'dataset' è³‡æ–™å¤¾ï¼\")\n",
        "    print(\"è«‹åœ¨å·¦å´æª”æ¡ˆå€å»ºç«‹ 'dataset' è³‡æ–™å¤¾ï¼Œä¸¦ç¢ºèªçµæ§‹å¦‚ä¸‹ï¼š\")\n",
        "    print(\"dataset/train/raccoon (æ”¾å…¥æµ£ç†Šåœ–)\")\n",
        "    print(\"dataset/train/tanuki  (æ”¾å…¥ç‹¸è²“åœ–)\")\n",
        "    print(\"dataset/train/other   (æ”¾å…¥å…¶ä»–åœ–)\")\n",
        "else:\n",
        "    print(\"âœ… ç’°å¢ƒèˆ‡è³‡æ–™å¤¾æª¢æŸ¥å®Œç•¢ï¼Œè«‹ç¹¼çºŒä¸‹ä¸€æ­¥ã€‚\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import shutil # Import shutil for directory removal\n",
        "\n",
        "def train_pipeline():\n",
        "    DATA_DIR = 'dataset'\n",
        "    MODEL_SAVE_PATH = 'raccoon_tanuki_model.pth'\n",
        "\n",
        "    if not os.path.exists(DATA_DIR):\n",
        "        print(\"âŒ éŒ¯èª¤ï¼šæ²’æœ‰è³‡æ–™ï¼Œç„¡æ³•è¨“ç·´ã€‚è«‹å…ˆä¸Šå‚³åœ–ç‰‡ã€‚\")\n",
        "        return\n",
        "\n",
        "    # æ¸…ç† .ipynb_checkpoints è³‡æ–™å¤¾ï¼Œé¿å… ImageFolder èª¤åˆ¤ç‚ºé¡åˆ¥\n",
        "    for phase in ['train', 'val']:\n",
        "        checkpoints_path = os.path.join(DATA_DIR, phase, '.ipynb_checkpoints')\n",
        "        if os.path.exists(checkpoints_path) and os.path.isdir(checkpoints_path):\n",
        "            print(f\"ğŸ—‘ï¸ åµæ¸¬åˆ°ä¸¦ç§»é™¤ç„¡æ•ˆçš„è³‡æ–™å¤¾: {checkpoints_path}\")\n",
        "            shutil.rmtree(checkpoints_path)\n",
        "\n",
        "    # è¨­å®šè£ç½®\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"ğŸš€ ä½¿ç”¨è£ç½®é€²è¡Œè¨“ç·´: {device}\")\n",
        "\n",
        "    # å½±åƒé è™•ç†\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.RandomHorizontalFlip(), # è³‡æ–™å¢å¼·\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        # é©—è­‰é›†è‹¥æ²’å»ºï¼Œé€™è£¡æœƒè‡ªå‹•fallbackåªç”¨è¨“ç·´é›†ï¼Œæ–¹ä¾¿æ¸¬è©¦\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    # è®€å–è³‡æ–™\n",
        "    # å¦‚æœåªæœ‰ train è³‡æ–™å¤¾ï¼Œå°±åªè®€ train\n",
        "    phases = ['train']\n",
        "    if os.path.exists(os.path.join(DATA_DIR, 'val')):\n",
        "        phases.append('val')\n",
        "\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x]) for x in phases}\n",
        "    dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in phases}\n",
        "    class_names = image_datasets['train'].classes\n",
        "\n",
        "    print(f\"ğŸ“‚ åµæ¸¬åˆ°çš„é¡åˆ¥: {class_names}\")\n",
        "\n",
        "    # è¼‰å…¥ ResNet18\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    # è¨“ç·´è¿´åœˆ (è¨­ç‚º 5 epoch å¿«é€Ÿæ¸¬è©¦ï¼Œæƒ³è¦æº–ä¸€é»å¯æ”¹æˆ 10-15)\n",
        "    epochs = 5\n",
        "    print(f\"ğŸ’ª é–‹å§‹è¨“ç·´ (å…± {epochs} è¼ª)...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders['train']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(image_datasets['train'])\n",
        "        epoch_acc = running_corrects.double() / len(image_datasets['train'])\n",
        "        print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    # å„²å­˜æ¨¡å‹\n",
        "    torch.save({'model_state_dict': model.state_dict(), 'classes': class_names}, MODEL_SAVE_PATH)\n",
        "    print(f\"âœ… æ¨¡å‹å·²å„²å­˜ç‚º: {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# åŸ·è¡Œè¨“ç·´\n",
        "train_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l5VA1WiE5uU",
        "outputId": "9151a7ef-1716-45ab-fbee-31ec45628968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—‘ï¸ åµæ¸¬åˆ°ä¸¦ç§»é™¤ç„¡æ•ˆçš„è³‡æ–™å¤¾: dataset/val/.ipynb_checkpoints\n",
            "ğŸš€ ä½¿ç”¨è£ç½®é€²è¡Œè¨“ç·´: cpu\n",
            "ğŸ“‚ åµæ¸¬åˆ°çš„é¡åˆ¥: ['other', 'raccoon', 'tanuki']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 166MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’ª é–‹å§‹è¨“ç·´ (å…± 5 è¼ª)...\n",
            "Epoch 1/5 - Loss: 0.9280 Acc: 0.5556\n",
            "Epoch 2/5 - Loss: 0.4502 Acc: 0.8889\n",
            "Epoch 3/5 - Loss: 0.2674 Acc: 0.9259\n",
            "Epoch 4/5 - Loss: 0.1880 Acc: 0.9605\n",
            "Epoch 5/5 - Loss: 0.1302 Acc: 0.9852\n",
            "âœ… æ¨¡å‹å·²å„²å­˜ç‚º: raccoon_tanuki_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "# --- é é¢åŸºæœ¬è¨­å®š ---\n",
        "st.set_page_config(page_title=\"æµ£ç†Š vs ç‹¸è²“\", page_icon=\"ğŸ¦\")\n",
        "st.title(\"ğŸ¦ æµ£ç†Š vs ç‹¸è²“ AI è¾¨è­˜å™¨\")\n",
        "st.write(\"ç‹€æ…‹ï¼šæº–å‚™å°±ç·’ï¼Œè«‹ä¸Šå‚³åœ–ç‰‡ã€‚\")\n",
        "\n",
        "# --- åƒæ•¸è¨­å®š ---\n",
        "MODEL_PATH = 'raccoon_tanuki_model.pth'\n",
        "CONFIDENCE_THRESHOLD = 0.6\n",
        "\n",
        "# --- è¼‰å…¥æ¨¡å‹ (ç§»é™¤ Cache ä»¥ç¢ºä¿ç©©å®šæ€§) ---\n",
        "def get_model():\n",
        "    device = torch.device(\"cpu\")\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        return None, None, None\n",
        "\n",
        "    try:\n",
        "        checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
        "        class_names = checkpoint['classes']\n",
        "\n",
        "        # å»ºç«‹æ¨¡å‹\n",
        "        model = models.resnet18(weights=None)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model.eval()\n",
        "        return model, class_names, device\n",
        "    except:\n",
        "        return None, None, None\n",
        "\n",
        "# --- å½±åƒè™•ç† ---\n",
        "def process_image(image):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "# --- Grad-CAM ---\n",
        "def get_gradcam(model, input_tensor, original_image):\n",
        "    target_layers = [model.layer4[-1]]\n",
        "    cam = GradCAM(model=model, target_layers=target_layers)\n",
        "    grayscale_cam = cam(input_tensor=input_tensor, targets=None)[0, :]\n",
        "    img_resized = np.array(original_image.resize((224, 224))) / 255.0\n",
        "    return show_cam_on_image(img_resized, grayscale_cam, use_rgb=True)\n",
        "\n",
        "# --- ä¸»ç¨‹å¼é‚è¼¯ ---\n",
        "# 1. å…ˆé¡¯ç¤ºä¸Šå‚³æŒ‰éˆ• (ç¢ºä¿é€™å€‹ UI æ°¸é å­˜åœ¨)\n",
        "uploaded_file = st.file_uploader(\"ğŸ“· è«‹é¸æ“‡ä¸€å¼µ JPG æˆ– PNG åœ–ç‰‡\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "# 2. å¦‚æœæœ‰ä¸Šå‚³ï¼Œæ‰é–‹å§‹è¼‰å…¥æ¨¡å‹ä¸¦é æ¸¬\n",
        "if uploaded_file is not None:\n",
        "    st.write(\"ğŸ”„ æ­£åœ¨åˆ†æä¸­...\")\n",
        "\n",
        "    # è¼‰å…¥æ¨¡å‹\n",
        "    model, class_names, device = get_model()\n",
        "\n",
        "    if model is None:\n",
        "        st.error(\"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼Œè«‹æª¢æŸ¥ GitHub æˆ– Colab æª”æ¡ˆå€ã€‚\")\n",
        "    else:\n",
        "        try:\n",
        "            # è®€åœ–èˆ‡é æ¸¬\n",
        "            image = Image.open(uploaded_file).convert('RGB')\n",
        "            input_tensor = process_image(image)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_tensor)\n",
        "                probs = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
        "\n",
        "            top_prob, top_idx = torch.max(probs, 0)\n",
        "            top_class = class_names[top_idx]\n",
        "            top_prob_val = top_prob.item()\n",
        "\n",
        "            # --- é¡¯ç¤ºçµæœå€ ---\n",
        "            st.markdown(\"---\")\n",
        "            col1, col2 = st.columns(2)\n",
        "\n",
        "            with col1:\n",
        "                st.image(image, caption='ä½ çš„åœ–ç‰‡', use_column_width=True)\n",
        "\n",
        "            with col2:\n",
        "                st.subheader(\"ğŸ“Š åˆ†æçµæœ\")\n",
        "\n",
        "                # OOD åˆ¤æ–·\n",
        "                is_ood = False\n",
        "                if top_class == 'other':\n",
        "                    is_ood = True\n",
        "                    st.error(\"ğŸš« çµæœï¼šä»¥ä¸Šçš†é (Other)\")\n",
        "                elif top_prob_val < CONFIDENCE_THRESHOLD:\n",
        "                    is_ood = True\n",
        "                    st.warning(f\"ğŸ¤” çµæœï¼šä¸ç¢ºå®š (ä¼¼ {top_class}?)\")\n",
        "                    st.write(f\"ä¿¡å¿ƒåº¦ {top_prob_val*100:.1f}% å¤ªä½ã€‚\")\n",
        "                else:\n",
        "                    if top_class == 'raccoon':\n",
        "                        st.success(\"ğŸ¦ çµæœï¼šæµ£ç†Š (Raccoon)\")\n",
        "                    elif top_class == 'tanuki':\n",
        "                        st.info(\"ğŸ‚ çµæœï¼šç‹¸è²“ (Tanuki)\")\n",
        "                    st.metric(\"ä¿¡å¿ƒåº¦\", f\"{top_prob_val*100:.1f}%\")\n",
        "\n",
        "                st.bar_chart({name: float(p) for name, p in zip(class_names, probs)})\n",
        "\n",
        "            # --- é€²éšåŠŸèƒ½ (ç†±é»åœ– + æ•™å­¸) ---\n",
        "            if not is_ood:\n",
        "                st.markdown(\"---\")\n",
        "                st.subheader(\"ğŸ”¥ AI è¦–è¦ºç†±é»\")\n",
        "                cam_vis = get_gradcam(model, input_tensor, image)\n",
        "                st.image(cam_vis, caption='ç´…è‰²å€åŸŸç‚ºåˆ¤æ–·ä¾æ“š', width=350)\n",
        "\n",
        "                st.markdown(\"---\")\n",
        "                st.subheader(\"ğŸ“ ç‰¹å¾µæ¯”ä¸€æ¯”\")\n",
        "\n",
        "                # æ¨£å¼è¨­å®š\n",
        "                style_rac = \"border:2px solid #4CAF50; background:#e8f5e9\" if top_class == 'raccoon' else \"opacity:0.5\"\n",
        "                style_tan = \"border:2px solid #FF9800; background:#fff3e0\" if top_class == 'tanuki' else \"opacity:0.5\"\n",
        "\n",
        "                c1, c2 = st.columns(2)\n",
        "                with c1:\n",
        "                    st.markdown(f\"\"\"<div style=\"{style_rac}; padding:10px; border-radius:10px\">\n",
        "                    <h4 style=\"color:#2E7D32; text-align:center\">ğŸ¦ æµ£ç†Šç‰¹å¾µ</h4>\n",
        "                    <ul><li><b>å°¾å·´æœ‰ç’°ç´‹</b></li><li>äº”æŒ‡åˆ†é–‹ (åƒæ‰‹)</li><li>çœ¼ç½©åˆ†é–‹</li></ul></div>\"\"\", unsafe_allow_html=True)\n",
        "                with c2:\n",
        "                    st.markdown(f\"\"\"<div style=\"{style_tan}; padding:10px; border-radius:10px\">\n",
        "                    <h4 style=\"color:#EF6C00; text-align:center\">ğŸ‚ ç‹¸è²“ç‰¹å¾µ</h4>\n",
        "                    <ul><li><b>å°¾å·´ç„¡ç’°ç´‹</b></li><li>è…³æŒåƒç‹—è‚‰å¢Š</li><li>çœ¼ç½©ç›¸é€£</li></ul></div>\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"ç™¼ç”ŸéŒ¯èª¤: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYYqhyQeE8cm",
        "outputId": "b81ba242-3493-4425-ffcc-82d30fa70c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import re\n",
        "import subprocess\n",
        "\n",
        "# 1. å…ˆæ®ºæ‰æ‰€æœ‰èˆŠçš„ç¨‹åº (æ¸…ç†ç’°å¢ƒ)\n",
        "os.system(\"pkill -f streamlit\")\n",
        "os.system(\"pkill -f cloudflared\")\n",
        "\n",
        "# 2. ç¢ºä¿ Cloudflare æœ‰å®‰è£ (å¦‚æœå‰›å‰›è£éæœƒè·³é)\n",
        "if not os.path.exists(\"cloudflared.deb\"):\n",
        "    print(\"ğŸ“¥ ä¸‹è¼‰é€£ç·šå·¥å…·...\")\n",
        "    os.system(\"curl -L --output cloudflared.deb https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb > /dev/null 2>&1\")\n",
        "    os.system(\"sudo dpkg -i cloudflared.deb > /dev/null 2>&1\")\n",
        "\n",
        "# 3. å•Ÿå‹• Streamlit (èƒŒæ™¯åŸ·è¡Œ)\n",
        "print(\"ğŸš€ å•Ÿå‹• Streamlit...\")\n",
        "os.system(\"streamlit run app.py --server.enableCORS=false --server.enableXsrfProtection=false > /dev/null 2>&1 &\")\n",
        "\n",
        "# 4. å•Ÿå‹• Cloudflare Tunnel ä¸¦å°‡ç¶²å€å¯«å…¥ log æª”\n",
        "print(\"ğŸ”— æ­£åœ¨å»ºç«‹é€£ç·š (å°‡è¼¸å‡ºå¯«å…¥ tunnel.log)...\")\n",
        "os.system(\"nohup cloudflared tunnel --url http://localhost:8501 > tunnel.log 2>&1 &\")\n",
        "\n",
        "# 5. å¾ªç’°æª¢æŸ¥ log æª”ï¼Œç›´åˆ°æŠ“åˆ°ç¶²å€\n",
        "print(\"â³ ç­‰å¾…ç¶²å€ç”Ÿæˆ (ç´„ 5-10 ç§’)...\")\n",
        "found_url = False\n",
        "\n",
        "for i in range(30): # æœ€å¤šç­‰ 30 ç§’\n",
        "    time.sleep(1)\n",
        "    if os.path.exists(\"tunnel.log\"):\n",
        "        with open(\"tunnel.log\", \"r\") as f:\n",
        "            content = f.read()\n",
        "            # å°‹æ‰¾ .trycloudflare.com çš„ç¶²å€\n",
        "            match = re.search(r'https://[a-zA-Z0-9-]+\\.trycloudflare\\.com', content)\n",
        "            if match:\n",
        "                print(\"\\nğŸ‘‡ğŸ‘‡ğŸ‘‡ æˆåŠŸï¼è«‹é»æ“Šä¸‹æ–¹é€£çµ (å…å¯†ç¢¼) ğŸ‘‡ğŸ‘‡ğŸ‘‡\\n\")\n",
        "                print(f\"ğŸ”— {match.group(0)}\")\n",
        "                print(\"\\nğŸ‘†ğŸ‘†ğŸ‘† é»æ“Šé€™å€‹é€£çµé–‹å•Ÿ App ğŸ‘†ğŸ‘†ğŸ‘†\\n\")\n",
        "                found_url = True\n",
        "                break\n",
        "\n",
        "if not found_url:\n",
        "    print(\"âš ï¸ å¥‡æ€ªï¼Œé‚„æ˜¯æ²’æŠ“åˆ°ã€‚è«‹åœ¨å·¦å´æª”æ¡ˆå€æ‰“é–‹ 'tunnel.log' çœ‹çœ‹è£¡é¢æœ‰æ²’æœ‰ç¶²å€ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUgp5LlrE_Iu",
        "outputId": "3faf938b-659a-4a03-c42f-806be26791da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ å•Ÿå‹• Streamlit...\n",
            "ğŸ”— æ­£åœ¨å»ºç«‹é€£ç·š (å°‡è¼¸å‡ºå¯«å…¥ tunnel.log)...\n",
            "â³ ç­‰å¾…ç¶²å€ç”Ÿæˆ (ç´„ 5-10 ç§’)...\n",
            "\n",
            "ğŸ‘‡ğŸ‘‡ğŸ‘‡ æˆåŠŸï¼è«‹é»æ“Šä¸‹æ–¹é€£çµ (å…å¯†ç¢¼) ğŸ‘‡ğŸ‘‡ğŸ‘‡\n",
            "\n",
            "ğŸ”— https://wishlist-seats-booth-dental.trycloudflare.com\n",
            "\n",
            "ğŸ‘†ğŸ‘†ğŸ‘† é»æ“Šé€™å€‹é€£çµé–‹å•Ÿ App ğŸ‘†ğŸ‘†ğŸ‘†\n",
            "\n"
          ]
        }
      ]
    }
  ]
}