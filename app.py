import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np
import os
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image

# --- é é¢åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="æµ£ç†Š vs ç‹¸è²“", page_icon="ğŸ¦")
st.title("ğŸ¦ æµ£ç†Š vs ç‹¸è²“ AI è¾¨è­˜å™¨")
st.write("ç‹€æ…‹ï¼šæº–å‚™å°±ç·’ï¼Œè«‹ä¸Šå‚³åœ–ç‰‡ã€‚")

# --- åƒæ•¸è¨­å®š ---
MODEL_PATH = 'raccoon_tanuki_model.pth'
CONFIDENCE_THRESHOLD = 0.6 

# --- è¼‰å…¥æ¨¡å‹ (ç§»é™¤ Cache ä»¥ç¢ºä¿ç©©å®šæ€§) ---
def get_model():
    device = torch.device("cpu")
    if not os.path.exists(MODEL_PATH):
        return None, None, None
    
    try:
        checkpoint = torch.load(MODEL_PATH, map_location=device)
        class_names = checkpoint['classes']
        
        # å»ºç«‹æ¨¡å‹
        model = models.resnet18(weights=None)
        num_ftrs = model.fc.in_features
        model.fc = nn.Linear(num_ftrs, len(class_names))
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        return model, class_names, device
    except:
        return None, None, None

# --- å½±åƒè™•ç† ---
def process_image(image):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    return transform(image).unsqueeze(0)

# --- Grad-CAM ---
def get_gradcam(model, input_tensor, original_image):
    target_layers = [model.layer4[-1]]
    cam = GradCAM(model=model, target_layers=target_layers)
    grayscale_cam = cam(input_tensor=input_tensor, targets=None)[0, :]
    img_resized = np.array(original_image.resize((224, 224))) / 255.0
    return show_cam_on_image(img_resized, grayscale_cam, use_rgb=True)

# --- ä¸»ç¨‹å¼é‚è¼¯ ---
# 1. å…ˆé¡¯ç¤ºä¸Šå‚³æŒ‰éˆ• (ç¢ºä¿é€™å€‹ UI æ°¸é å­˜åœ¨)
uploaded_file = st.file_uploader("ğŸ“· è«‹é¸æ“‡ä¸€å¼µ JPG æˆ– PNG åœ–ç‰‡", type=["jpg", "jpeg", "png"])

# 2. å¦‚æœæœ‰ä¸Šå‚³ï¼Œæ‰é–‹å§‹è¼‰å…¥æ¨¡å‹ä¸¦é æ¸¬
if uploaded_file is not None:
    st.write("ğŸ”„ æ­£åœ¨åˆ†æä¸­...")
    
    # è¼‰å…¥æ¨¡å‹
    model, class_names, device = get_model()
    
    if model is None:
        st.error("æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼Œè«‹æª¢æŸ¥ GitHub æˆ– Colab æª”æ¡ˆå€ã€‚")
    else:
        try:
            # è®€åœ–èˆ‡é æ¸¬
            image = Image.open(uploaded_file).convert('RGB')
            input_tensor = process_image(image)
            
            with torch.no_grad():
                outputs = model(input_tensor)
                probs = torch.nn.functional.softmax(outputs, dim=1)[0]
            
            top_prob, top_idx = torch.max(probs, 0)
            top_class = class_names[top_idx]
            top_prob_val = top_prob.item()
            
            # --- é¡¯ç¤ºçµæœå€ ---
            st.markdown("---")
            col1, col2 = st.columns(2)
            
            with col1:
                st.image(image, caption='ä½ çš„åœ–ç‰‡', use_column_width=True)
            
            with col2:
                st.subheader("ğŸ“Š åˆ†æçµæœ")
                
                # OOD åˆ¤æ–·
                is_ood = False
                if top_class == 'other':
                    is_ood = True
                    st.error("ğŸš« çµæœï¼šä»¥ä¸Šçš†é (Other)")
                elif top_prob_val < CONFIDENCE_THRESHOLD:
                    is_ood = True
                    st.warning(f"ğŸ¤” çµæœï¼šä¸ç¢ºå®š (ä¼¼ {top_class}?)")
                    st.write(f"ä¿¡å¿ƒåº¦ {top_prob_val*100:.1f}% å¤ªä½ã€‚")
                else:
                    if top_class == 'raccoon':
                        st.success("ğŸ¦ çµæœï¼šæµ£ç†Š (Raccoon)")
                    elif top_class == 'tanuki':
                        st.info("ğŸ‚ çµæœï¼šç‹¸è²“ (Tanuki)")
                    st.metric("ä¿¡å¿ƒåº¦", f"{top_prob_val*100:.1f}%")

                st.bar_chart({name: float(p) for name, p in zip(class_names, probs)})

            # --- é€²éšåŠŸèƒ½ (ç†±é»åœ– + æ•™å­¸) ---
            if not is_ood:
                st.markdown("---")
                st.subheader("ğŸ”¥ AI è¦–è¦ºç†±é»")
                cam_vis = get_gradcam(model, input_tensor, image)
                st.image(cam_vis, caption='ç´…è‰²å€åŸŸç‚ºåˆ¤æ–·ä¾æ“š', width=350)
                
                st.markdown("---")
                st.subheader("ğŸ“ ç‰¹å¾µæ¯”ä¸€æ¯”")
                
                # æ¨£å¼è¨­å®š
                style_rac = "border:2px solid #4CAF50; background:#e8f5e9" if top_class == 'raccoon' else "opacity:0.5"
                style_tan = "border:2px solid #FF9800; background:#fff3e0" if top_class == 'tanuki' else "opacity:0.5"
                
                c1, c2 = st.columns(2)
                with c1:
                    st.markdown(f"""<div style="{style_rac}; padding:10px; border-radius:10px">
                    <h4 style="color:#2E7D32; text-align:center">ğŸ¦ æµ£ç†Šç‰¹å¾µ</h4>
                    <ul><li><b>å°¾å·´æœ‰ç’°ç´‹</b></li><li>äº”æŒ‡åˆ†é–‹ (åƒæ‰‹)</li><li>çœ¼ç½©åˆ†é–‹</li></ul></div>""", unsafe_allow_html=True)
                with c2:
                    st.markdown(f"""<div style="{style_tan}; padding:10px; border-radius:10px">
                    <h4 style="color:#EF6C00; text-align:center">ğŸ‚ ç‹¸è²“ç‰¹å¾µ</h4>
                    <ul><li><b>å°¾å·´ç„¡ç’°ç´‹</b></li><li>è…³æŒåƒç‹—è‚‰å¢Š</li><li>çœ¼ç½©ç›¸é€£</li></ul></div>""", unsafe_allow_html=True)

        except Exception as e:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
